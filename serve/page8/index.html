<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Full Contact Philanthropy</title>
  <meta name="description" content="Social sector commentary.
">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://fullcontactphilanthropy.com/page8/">
  <link rel="alternate" type="application/rss+xml" title="Full Contact Philanthropy" href="http://fullcontactphilanthropy.com/feed.xml" />
  <!-- google fonts -->
  <link href='http://fonts.googleapis.com/css?family=Crimson+Text' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!-- font awesome -->
  <link rel="stylesheet" href="/assets/font-awesome/css/font-awesome.min.css" />
</head>


  <body>

    <header class="site-header">
  <div class="wrapper">
    <div class="site-title">
      <a  href="/" style="text-align: center'">Full Contact Philanthropy</a>
    </div>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
        
          
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
          <a class="page-link" href="/Projects/">Projects</a>
          
        
          
        
          
          <a class="page-link" href="/archive/">Archive</a>
          
        
          
          <a class="page-link" href="/subscribe/">Subscribe</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <!-- subscribe -->

          <a class="page-link" href="http://feeds.feedburner.com/fcp">
            <i class="fa fa-rss"></i>
          </a>

          <a class="page-link" href="https://twitter.com/david_henderson">
            <i class="fa fa-twitter"></i>
          </a>
      </div>
    </nav>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="home">

  
    <div class="post">

      <header class="post-header">
        <h1 class="post-title"><a href="/2012/11/15/the-trouble-with-benchmarks/">The trouble with benchmarks</a></h1>
        <p class="post-meta">
          Nov 15, 2012 &bull;
          <a href="/2012/11/15/the-trouble-with-benchmarks/"><i class="fa fa-link"></i></a>
        </p>
      </header>

      <article class="post-content">
        <p>I just got back from the annual <a href="http://www.independentsector.org/">Independent Sector</a> conference, which brings together non-profits, foundations, and self-promoting consultants (sorry about that) to discuss the direction of philanthropy.</p>
<p>The theme of the conference echoed that of the online philanthro-sphere, namely, most every session and discussion had something to do with data. I had some nice chats with folks about the emerging <a href="http://www.marketsforgood.org/">Markets for Good</a> platform, attended a session on using communal indicators to drive <a href="http://www.ssireview.org/articles/entry/collective_impact">collective impact</a>, and heard one too many pitches about how this or that consulting firm had the evaluation game pretty much locked up.</p>
<p>What many of these conversations had in common was a focus on setting benchmarks to compare progress against. Benchmarking is a quick and dirty tool for trying to estimate an effect over time, but it can be misleading, a fact that was not discussed in any of the sessions I attended.</p>
<p>Benchmarks essentially require one to measure an indicator level at an initial point in time, using that initial measure as a baseline for the future.</p>
<p>For example, a workforce development program might measure the percentage of people in its programs who found work in the last year, using that percentage as a baseline to compare future employment rates against. A year later, the program would look at this year's employment rate and compare it against last year's benchmarks.</p>
<p>In this simplistic scenario, one might assume that if the employment rate is better this year than last year's baseline, then the program is <em>doing better</em>, and if this year's employment rate is below the baseline then it is <em>doing worse</em>. But, as the title of this post gives away, there are some things to consider when using baselines.</p>
<p>As I have written in the past, social sciences are particularly complex because there are so many external factors outside our program interventions that affect the lives of those we aim to serve. In the employment baseline example, a worsening economy is likely to have a larger effect than the employment services themselves, all but assuring that the next year's employment rate will be below the baseline, <em>even if the program was more effective in its second year</em>.</p>
<p>Under the collective impact benchmarking model, we would collectively flog ourselves for results outside of our control. Likewise, we can also see the opposite effect, whereby we celebrate better outcomes against a previous benchmark when the upward swing is not attributable to our own efforts.</p>
<p>So, is benchmarking useless? No, but it also should not be confused with impact. A mantra I preach to my customers and brought up in many conversations at the Independent Sector conference is that it is equally important to understand what your data does say, as well as to understand what it does not.</p>
<p>The simple difference in two outcomes from time A to time B is not necessarily program impact, and cannot necessarily be attributed to our awesomeness.</p>
<p>Benchmarking tells us if an outcome is higher or lower than it was in the previous period. But subtraction is not really analysis. The analysis is trying to tease out the "why". Why did an outcome go up or down. Was it the result of something we did or some external factors? If the change is attributable to external factors, what are those factors?</p>
<p>In short, benchmarks can help you figure out which questions to ask, but benchmarking itself does not provide many answers.</p>
<p>I'm encouraged by the buzz around using data and analytics, but am cautious that data is kind of like fire, and it's important that we know what we are doing with it, lest we set ourselves ablaze.</p>

      </article>

    </div>

    <div style="font-size: 2em; color: #DDD; margin-bottom: 40px; text-align: center;">&#8497;</div>
  
    <div class="post">

      <header class="post-header">
        <h1 class="post-title"><a href="/2012/09/19/if-you-had-to-choose-between-an-evaluator-or-a-marketer/">If you had to choose between an evaluator or a marketer</a></h1>
        <p class="post-meta">
          Sep 19, 2012 &bull;
          <a href="/2012/09/19/if-you-had-to-choose-between-an-evaluator-or-a-marketer/"><i class="fa fa-link"></i></a>
        </p>
      </header>

      <article class="post-content">
        <p>Earlier this week I asked the following question on Twitter</p>
<blockquote><p>If you had to choose between an evaluator or a marketer for your #nonprofit org, which would you pick and why?</p></blockquote>
<p>I had plenty of interest in the question, but only one answer. <a href="https://twitter.com/AnnKEmery">Ann Emery</a> pointed to a 2010 study by the Innovation Network about the <a href="http://www.innonet.org/client_docs/innonet-state-of-evaluation-2010.pdf">State of Evaluation in 2010</a>. The salient point from the report that <a href="https://twitter.com/AnnKEmery/status/247814184052588546">Ann pointed out</a> is that in an online survey of over 800 non-profit organizations across the United States, "fundraising is #1 priority in nonprofits while evaluation is #9...".</p>
<p>This statistic provides some support for the open secret that organizations <em>prefer</em> investing in marketing over evaluation, but it doesn't answer the second part of my original question, <em>why</em> do organizations choose marketing over evaluation?</p>
<p>While not intentionally an answer to this question, a nonprofit I have been almost working with for the last year provides some insight. This organization is relatively young, small nonprofit that has found itself a media darling in certain circles. It plays lip service to a desire to evaluate its findings but insists that anyone who look at their numbers be properly vetted (read already a believer in this agency's approach).</p>
<p>Evaluators are inquisitive, and skeptical, by nature. A hypothesis test assumes there is no effect, rejecting this assumption only in the face of convincing evidence. Evaluators do the same thing.</p>
<p>This organization (not-uniquely) starts from the standpoint that its impact is a given. In that mindset, evaluators can only <em>disprove</em> your asserted greatness. Thinking of it that way, I'm not sure I'd hire an evaluator either.</p>
<p>An investment in marketing however brings accolades from the press, photo ops with politicians and the adoration (and financial support) of the general public. So really a choice between marketing and evaluation is a choice between fame and fortune versus the possibility of uncovering that the project you have invested in for over half a decade doesn't do what you thought it did.</p>
<p>In this way, choosing the marketing consultant is the <em>only</em> rational choice to make. Well, that is, if your organization's logic model defines an ultimate goal of self aggrandizement. If instead your target population are the people your agencies aims to serve, and the impact theory defines causal linkages between your interventions and something other than coverage in the New York Times, then an evaluator might be an okay idea after all.</p>
<p><strong>Consumer protections and false advertising</strong></p>
<p>Corporations invest in evaluating their products in part because better products are more competitive in the market place, but given the indirect funding nature of nonprofits, where the service recipient is not the <em>purchaser</em> of services, this incentive falls apart.</p>
<p>However, corporations also evaluate their products as to not run afoul of the various consumer protection regulations placed on businesses, including laws against falsely advertising one's products effects.</p>
<p>Imagine how different the sector would look if a similar standard were applied in the social sector. I have written before that <a href="http://idealistics.org/fcp/2012/07/03/evaluative-metrics-bring-truth-in-advertising-to-the-social-sector/">evaluation brings truth in advertising</a> to the social sector, but the real benefit would be to those we serve. The media story should be a secondary bi-product of a job well done. Instead, getting a good media story is the job, period.</p>

      </article>

    </div>

    <div style="font-size: 2em; color: #DDD; margin-bottom: 40px; text-align: center;">&#8497;</div>
  
    <div class="post">

      <header class="post-header">
        <h1 class="post-title"><a href="/2012/09/10/reporting-benefits-and-harms/">Reporting benefits and harms</a></h1>
        <p class="post-meta">
          Sep 10, 2012 &bull;
          <a href="/2012/09/10/reporting-benefits-and-harms/"><i class="fa fa-link"></i></a>
        </p>
      </header>

      <article class="post-content">
        <p>When I was in graduate school I had a fellowship that placed me with a community development financial intermediary. The organization, like most agencies in the social sector, was interested in demonstrating the effectiveness of its interventions.</p>
<p>I asked the executive director whether she wanted me to try to figure out what impact their work was having, or if she simply wanted me to report positive outcomes. Depending on how you look at a spreadsheet, you can make any gloomy picture look like rock-star results. To her credit, the executive director asked that I try to develop a real picture, not simply a rosy one.</p>
<p>But most of the pictures painted on organizations' "Impact" sections of their websites is of the Photoshop variety. There is a lot that is wrong with the way outcomes are reported, <a href="http://idealistics.org/fcp/2012/08/20/snake-oil-nonprofit-consultants-sell-outcomes-as-impact/">and conflated with impact</a> in social sector communications. One problem that I consistently see is reporting positive outcomes while neglecting to report the changes in those that experienced worse outcomes.</p>
<p>For example, the website of a celebrated family focused startup non-profit boasts that 20% of children in their program increased school attendance. Sounds great. But what happened to the other 80%? Did their attendance stay the same, did it get worse? And if so, by how much?</p>
<p>Increases always sound nice, but does any increase always outweigh a decrease? If 20% of students improved school attendance and 80% attended school <em>less</em> would we still consider the program a success?</p>
<p>Well, we probably need some more information to answer this question, information which is never provided in this type of <a href="http://idealistics.org/fcp/2012/07/03/evaluative-metrics-bring-truth-in-advertising-to-the-social-sector/">outcomes advertising</a>. We would at the very least need to know what an increase or decrease in attendance means. A 20% increase students attending classes sounds great, but if a kid was missing 30 days of school a year and now she misses 29, is the gain really as meaningful as it first sounded?</p>
<p>More importantly, what would have happened to these kids without the program? We need an estimate of their <em>counterfactual</em> (what the attendance of these youth would have been without this program's intervention) in order to truly determine whether we think this increase is reason to celebrate (or the possible decrease for a portion of the other 80% is cause for alarm).</p>
<p>Ultimately this comes down to a question of what I call reporting believability. Most of the impact results I have seen on organizations' websites are simply not believable, as they tend to claim outrages and unsubstantiated gains.</p>
<p>But these unsubstantiated claims of impact are big business. And if the social sector wants to truly move toward evidenced based programming, we need to figure out how to make it more profitable for organizations to report credible data instead of fantastical folly.</p>

      </article>

    </div>

    <div style="font-size: 2em; color: #DDD; margin-bottom: 40px; text-align: center;">&#8497;</div>
  
    <div class="post">

      <header class="post-header">
        <h1 class="post-title"><a href="/2012/09/06/too-many-indicators-means-a-whole-lot-of-nothing/">Too many indicators means a whole lot of nothing</a></h1>
        <p class="post-meta">
          Sep 6, 2012 &bull;
          <a href="/2012/09/06/too-many-indicators-means-a-whole-lot-of-nothing/"><i class="fa fa-link"></i></a>
        </p>
      </header>

      <article class="post-content">
        <p>Organizations have a tendency to want to collect every data point under the sun. I cannot tell you how many agencies I have contracted with that aim to collect things like social security numbers and criminal histories when these data points carry no decision relevance, and don't factor anywhere into the services they offer.</p>
<p>Even if organization executives are not concerned with putting those they serve through exhaustive questionnaires, they should be concerned about how overburdening front-line staff with administering lengthy intakes decreases data integrity. I have long advised my customers to keep their survey instruments short and to the point. The shorter your intake, the more likely you are to have every question answered. And if you are only asking a limited number of questions, every question should have been well thought out and be clearly relevant to decision making.</p>
<p>I'm in the process of working with some organizations to redesign their intake forms. One organization I'm working with was attempting to track over 300 indicators. Back in the original intake design phase the thinking was (as is common) that the more data you have the better. In hindsight, my customer realized that trying to collect so many indicators overlooked the implementation reality; it's a lot easier to say what you want than to go out and get it.</p>
<p>The following histogram shows the number of questions on the y-axis by the number of times those questions were answered on the x-axis over a year for this particular organization. Half of the questions were answered about ten times, with one-third of questions never being used.</p>
<p style="text-align: center;"><img class="aligncenter  wp-image-940" title="question_answer_hist.jpg" src="/assets/images/question_answer_hist.jpg.png" alt="" width="480" height="267" /></p>
<p>To be clear, this is not a case where the front-line staff was not collecting any data at all. There were a handful of questions with around 3,000 answers, and a reasonable number between 500 and 1,500 answers. The questions with the most answers were indicators that every front-line staffer found important, such as race and sex. The reason the question answers varies so greatly is that with so many questions to answer, no staffer was going to answer them all. Therefore, each staff person used her or his own judgment as to which questions were important to answer.</p>
<p>With so many holes in this data set, it's hard to draw much insight. To avoid running into this problem, organizations should tie each question directly to an outcome in their impact theories. This discipline helps prevent "question-creep", where new questions are asked out of curiosity rather than what actions can be taken with that feedback. Second, get front-line staff involved in the intake design process to ensure that all the data they need is being collected and that the questions, as worded, are practical and collectable.</p>

      </article>

    </div>

    <div style="font-size: 2em; color: #DDD; margin-bottom: 40px; text-align: center;">&#8497;</div>
  
    <div class="post">

      <header class="post-header">
        <h1 class="post-title"><a href="/2012/08/23/please-stop-developing-websites-that-list-nonprofits/">Please stop developing websites that list nonprofits</a></h1>
        <p class="post-meta">
          Aug 23, 2012 &bull;
          <a href="/2012/08/23/please-stop-developing-websites-that-list-nonprofits/"><i class="fa fa-link"></i></a>
        </p>
      </header>

      <article class="post-content">
        <p>Yet another website that catalogues non-profits was <a href="http://philanthropy.com/blogs/the-giveaway/new-web-site-informs-philanthropists-about-nonprofits/2967?cid=pt&amp;utm_source=pt&amp;utm_medium=en">released into the wild</a> earlier this week, as the Laura and John Arnold Foundation launched the <a href="http://www.givinglibrary.org/about-us">Giving Library</a>. For a sector that disdains duplicating efforts, maintaining <a href="http://www.greatnonprofits.org">online directories</a> of <a href="http://www.guidestar.org/">non-profit organizations</a> is a <a href="http://www.charitynavigator.org/">fairly crowded market</a>. What all of these efforts to create proprietary listings of non-profit organizations have in common is an imminent threat of extinction by Google, which has a pretty serious competitive advantage in the indexing game.</p>
<p>Developing listings of nonprofits is not necessary with modern search tools. While it is fairly trivial to find an organization that <em>wants</em> to take a donor's money, it is far more difficult to identify organizations that one believes will <em>maximize</em> their charitable dollars. To be fair, organizations like Great Nonprofits and Charity Navigator are attempting to solve this bigger problem of helping donors identify effective agencies to invest in, although neither provides compelling analysis to functionally move outside the sphere of simple cataloguing (yet).</p>
<p>Indeed, the growth in influence of <a href="http://givewell.org/">GiveWell</a> underscores the value of analysis over indexing. The problem of course is that the deeper analytic approach is research intensive, and does not scale. Therefore, we are instead bombarded with superficial efforts to simply create nonprofit listings or develop laughably linear four star rating systems.</p>
<p>And where is the evidence that donors <em>need</em> a website dedicated to listing non-profit organizations? Results of the <a href="http://themillennialimpact.com/wp-content/uploads/2012/06/TheMillennialImpactReport2012.pdf">2012 Millennial Impact Report</a> suggest that, at least among web-savvy donors between the ages of 20-35, people are perfectly capable of learning about non-profits through organizations' websites, newsletters, and social media channels without the assistance of intermediaries.</p>
<p>Which brings us back to the analysis problem. Donors do not need help <em>finding</em> organizations, they need help <em>selecting</em> organizations based on their evaluative criterion. GiveWell simplifies the process for a certain set of donors by articulating their own criterion and providing investment advice to donors who are inclined to adopt GiveWell's utility framework.</p>
<p>The more difficult issue then is to develop ways of matching donors to <em>effective</em> organizations that address issues that are consistent with the donor's own values. This is a matter of substantive impact evaluation and donor utility elicitation. Neither of which have anything to do with hiring a web design firm to throw up yet another nonprofit digital dumpster.</p>
<p>&nbsp;</p>

      </article>

    </div>

    <div style="font-size: 2em; color: #DDD; margin-bottom: 40px; text-align: center;">&#8497;</div>
  

  <!-- Pagination links -->
  <div class="pagination">
    
      <a href="" class="previous"><i class="fa fa-hand-o-left"></i> Previous</a>
    
    <span class="page_number">Page: 8 of 23</span>
    
      <a href="" class="next">Next <i class="fa fa-hand-o-right"></i></a>
    
  </div>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>David Henderson</li>
          <li><a href="mailto:david.henderson82@gmail.com">david.henderson82@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-1">
        <ul class="social-media-list">
          <li>
            <a href="http://feeds.feedburner.com/fcp">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </li>
          
          <li>
            <a href="https://twitter.com/david_henderson">
              <i class="fa fa-twitter"></i>
              <span class="username">david_henderson</span>
            </a>
          </li>
          


          <li>
            <a href="https://www.linkedin.com/in/davidihenderson">
              <i class="fa fa-linkedin"></i>
              LinkedIn
            </a>
          </li>


          
          <li>
            <a href="https://github.com/dhenderson">
              <i class="fa fa-github"></i>
              <span class="username">dhenderson</span>
            </a>
          </li>
          
        </ul>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
